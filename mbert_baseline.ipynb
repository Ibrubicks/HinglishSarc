{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# mBERT Baseline — Sarcasm Detection on Cleaned Hinglish Dataset\n",
                "\n",
                "This notebook trains a **multilingual BERT (mBERT)** baseline for binary sarcasm classification on the cleaned Hinglish dataset.\n",
                "\n",
                "Expected baseline F1: **~75%** (without data leakage).\n",
                "\n",
                "**Run this on Google Colab / Kaggle with a GPU runtime.**"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Install Dependencies"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install transformers datasets accelerate scikit-learn -q"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Imports & Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import random\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import torch\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "from transformers import (\n",
                "    BertTokenizer,\n",
                "    BertForSequenceClassification,\n",
                "    get_linear_schedule_with_warmup,\n",
                ")\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.metrics import (\n",
                "    classification_report,\n",
                "    f1_score,\n",
                "    accuracy_score,\n",
                "    confusion_matrix,\n",
                ")\n",
                "import matplotlib.pyplot as plt\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "# ────────────────────────────────────────────\n",
                "# CONFIG — tweak these as needed\n",
                "# ────────────────────────────────────────────\n",
                "MODEL_NAME   = 'bert-base-multilingual-cased'\n",
                "MAX_LEN      = 128\n",
                "BATCH_SIZE   = 32\n",
                "EPOCHS       = 5\n",
                "LR           = 2e-5\n",
                "SEED         = 42\n",
                "DATA_PATH    = 'Data/sarcasm_hinghlish_dataset_cleaned.csv'\n",
                "SAVE_DIR     = 'mbert_baseline'\n",
                "\n",
                "# Reproducibility\n",
                "random.seed(SEED)\n",
                "np.random.seed(SEED)\n",
                "torch.manual_seed(SEED)\n",
                "torch.cuda.manual_seed_all(SEED)\n",
                "\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f'Using device: {device}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Load & Split Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df = pd.read_csv(DATA_PATH)\n",
                "print(f'Total samples: {len(df)}')\n",
                "print(f'Label distribution:\\n{df[\"label\"].value_counts()}')\n",
                "print(f'\\nSample rows:')\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 70 / 15 / 15  split (stratified)\n",
                "train_df, temp_df = train_test_split(\n",
                "    df, test_size=0.30, random_state=SEED, stratify=df['label']\n",
                ")\n",
                "val_df, test_df = train_test_split(\n",
                "    temp_df, test_size=0.50, random_state=SEED, stratify=temp_df['label']\n",
                ")\n",
                "\n",
                "print(f'Train: {len(train_df)}  |  Val: {len(val_df)}  |  Test: {len(test_df)}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Tokenizer & Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
                "\n",
                "class SarcasmDataset(Dataset):\n",
                "    def __init__(self, texts, labels, tokenizer, max_len):\n",
                "        self.texts     = texts.reset_index(drop=True)\n",
                "        self.labels    = labels.reset_index(drop=True)\n",
                "        self.tokenizer = tokenizer\n",
                "        self.max_len   = max_len\n",
                "\n",
                "    def __len__(self):\n",
                "        return len(self.texts)\n",
                "\n",
                "    def __getitem__(self, idx):\n",
                "        text  = str(self.texts[idx])\n",
                "        label = int(self.labels[idx])\n",
                "        enc   = self.tokenizer.encode_plus(\n",
                "            text,\n",
                "            max_length=self.max_len,\n",
                "            truncation=True,\n",
                "            padding='max_length',\n",
                "            return_attention_mask=True,\n",
                "            return_tensors='pt',\n",
                "        )\n",
                "        return {\n",
                "            'input_ids':      enc['input_ids'].squeeze(0),\n",
                "            'attention_mask': enc['attention_mask'].squeeze(0),\n",
                "            'labels':         torch.tensor(label, dtype=torch.long),\n",
                "        }\n",
                "\n",
                "train_dataset = SarcasmDataset(train_df['text'], train_df['label'], tokenizer, MAX_LEN)\n",
                "val_dataset   = SarcasmDataset(val_df['text'],   val_df['label'],   tokenizer, MAX_LEN)\n",
                "test_dataset  = SarcasmDataset(test_df['text'],  test_df['label'],  tokenizer, MAX_LEN)\n",
                "\n",
                "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
                "val_loader   = DataLoader(val_dataset,   batch_size=BATCH_SIZE)\n",
                "test_loader  = DataLoader(test_dataset,  batch_size=BATCH_SIZE)\n",
                "\n",
                "print(f'Batches  →  train: {len(train_loader)}, val: {len(val_loader)}, test: {len(test_loader)}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Model, Optimizer & Scheduler"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model = BertForSequenceClassification.from_pretrained(\n",
                "    MODEL_NAME, num_labels=2\n",
                ").to(device)\n",
                "\n",
                "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=0.01)\n",
                "\n",
                "total_steps = len(train_loader) * EPOCHS\n",
                "scheduler   = get_linear_schedule_with_warmup(\n",
                "    optimizer,\n",
                "    num_warmup_steps=int(0.1 * total_steps),\n",
                "    num_training_steps=total_steps,\n",
                ")\n",
                "\n",
                "print(f'Total training steps: {total_steps}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Training Loop"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def train_epoch(model, loader, optimizer, scheduler, device):\n",
                "    model.train()\n",
                "    total_loss = 0\n",
                "    preds_all, labels_all = [], []\n",
                "\n",
                "    for batch in loader:\n",
                "        input_ids = batch['input_ids'].to(device)\n",
                "        attn_mask = batch['attention_mask'].to(device)\n",
                "        labels    = batch['labels'].to(device)\n",
                "\n",
                "        optimizer.zero_grad()\n",
                "        outputs = model(input_ids, attention_mask=attn_mask, labels=labels)\n",
                "        loss    = outputs.loss\n",
                "        logits  = outputs.logits\n",
                "\n",
                "        loss.backward()\n",
                "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
                "        optimizer.step()\n",
                "        scheduler.step()\n",
                "\n",
                "        total_loss += loss.item()\n",
                "        preds_all.extend(torch.argmax(logits, dim=1).cpu().numpy())\n",
                "        labels_all.extend(labels.cpu().numpy())\n",
                "\n",
                "    avg_loss = total_loss / len(loader)\n",
                "    acc  = accuracy_score(labels_all, preds_all)\n",
                "    f1   = f1_score(labels_all, preds_all, average='macro')\n",
                "    return avg_loss, acc, f1\n",
                "\n",
                "\n",
                "def eval_epoch(model, loader, device):\n",
                "    model.eval()\n",
                "    total_loss = 0\n",
                "    preds_all, labels_all = [], []\n",
                "\n",
                "    with torch.no_grad():\n",
                "        for batch in loader:\n",
                "            input_ids = batch['input_ids'].to(device)\n",
                "            attn_mask = batch['attention_mask'].to(device)\n",
                "            labels    = batch['labels'].to(device)\n",
                "\n",
                "            outputs = model(input_ids, attention_mask=attn_mask, labels=labels)\n",
                "            total_loss += outputs.loss.item()\n",
                "            preds_all.extend(torch.argmax(outputs.logits, dim=1).cpu().numpy())\n",
                "            labels_all.extend(labels.cpu().numpy())\n",
                "\n",
                "    avg_loss = total_loss / len(loader)\n",
                "    acc  = accuracy_score(labels_all, preds_all)\n",
                "    f1   = f1_score(labels_all, preds_all, average='macro')\n",
                "    return avg_loss, acc, f1, preds_all, labels_all"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "history = {'train_loss': [], 'val_loss': [], 'train_f1': [], 'val_f1': []}\n",
                "best_val_f1 = 0.0\n",
                "\n",
                "for epoch in range(1, EPOCHS + 1):\n",
                "    train_loss, train_acc, train_f1 = train_epoch(\n",
                "        model, train_loader, optimizer, scheduler, device\n",
                "    )\n",
                "    val_loss, val_acc, val_f1, _, _ = eval_epoch(\n",
                "        model, val_loader, device\n",
                "    )\n",
                "\n",
                "    history['train_loss'].append(train_loss)\n",
                "    history['val_loss'].append(val_loss)\n",
                "    history['train_f1'].append(train_f1)\n",
                "    history['val_f1'].append(val_f1)\n",
                "\n",
                "    print(\n",
                "        f'Epoch {epoch}/{EPOCHS}  |  '\n",
                "        f'Train Loss: {train_loss:.4f}  Acc: {train_acc:.4f}  F1: {train_f1:.4f}  |  '\n",
                "        f'Val Loss: {val_loss:.4f}  Acc: {val_acc:.4f}  F1: {val_f1:.4f}'\n",
                "    )\n",
                "\n",
                "    # Save best model checkpoint\n",
                "    if val_f1 > best_val_f1:\n",
                "        best_val_f1 = val_f1\n",
                "        os.makedirs(SAVE_DIR, exist_ok=True)\n",
                "        model.save_pretrained(SAVE_DIR)\n",
                "        tokenizer.save_pretrained(SAVE_DIR)\n",
                "        print(f'  ✓ Best model saved (val F1: {best_val_f1:.4f})')\n",
                "\n",
                "print(f'\\nTraining complete. Best validation F1: {best_val_f1:.4f}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Training Curves"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "axes[0].plot(history['train_loss'], label='Train Loss')\n",
                "axes[0].plot(history['val_loss'],   label='Val Loss')\n",
                "axes[0].set_title('Loss over Epochs')\n",
                "axes[0].set_xlabel('Epoch')\n",
                "axes[0].set_ylabel('Loss')\n",
                "axes[0].legend()\n",
                "\n",
                "axes[1].plot(history['train_f1'], label='Train F1')\n",
                "axes[1].plot(history['val_f1'],   label='Val F1')\n",
                "axes[1].set_title('Macro F1 over Epochs')\n",
                "axes[1].set_xlabel('Epoch')\n",
                "axes[1].set_ylabel('F1')\n",
                "axes[1].legend()\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('training_curves.png', dpi=150)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Evaluate on Test Set"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load best checkpoint\n",
                "best_model = BertForSequenceClassification.from_pretrained(SAVE_DIR).to(device)\n",
                "\n",
                "test_loss, test_acc, test_f1, test_preds, test_labels = eval_epoch(\n",
                "    best_model, test_loader, device\n",
                ")\n",
                "\n",
                "print('═' * 60)\n",
                "print(f'  TEST RESULTS')\n",
                "print(f'  Loss:     {test_loss:.4f}')\n",
                "print(f'  Accuracy: {test_acc:.4f}')\n",
                "print(f'  Macro F1: {test_f1:.4f}')\n",
                "print('═' * 60)\n",
                "print()\n",
                "print(classification_report(\n",
                "    test_labels, test_preds,\n",
                "    target_names=['Not Sarcastic (0)', 'Sarcastic (1)']\n",
                "))\n",
                "print('Confusion Matrix:')\n",
                "print(confusion_matrix(test_labels, test_preds))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Quick Inference Demo"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def predict(text, model, tokenizer, device, max_len=MAX_LEN):\n",
                "    model.eval()\n",
                "    enc = tokenizer.encode_plus(\n",
                "        text,\n",
                "        max_length=max_len,\n",
                "        truncation=True,\n",
                "        padding='max_length',\n",
                "        return_tensors='pt',\n",
                "    )\n",
                "    input_ids = enc['input_ids'].to(device)\n",
                "    attn_mask = enc['attention_mask'].to(device)\n",
                "\n",
                "    with torch.no_grad():\n",
                "        logits = model(input_ids, attention_mask=attn_mask).logits\n",
                "\n",
                "    probs = torch.softmax(logits, dim=1).cpu().numpy()[0]\n",
                "    label = int(np.argmax(probs))\n",
                "    return {\n",
                "        'text':  text,\n",
                "        'label': 'Sarcastic' if label == 1 else 'Not Sarcastic',\n",
                "        'confidence': f'{probs[label]:.2%}',\n",
                "    }\n",
                "\n",
                "# Test examples\n",
                "examples = [\n",
                "    \"Haan bilkul, sab kuch perfect chal raha hai\",\n",
                "    \"Aaj bahut productive din tha, sab kaam complete ho gaya\",\n",
                "    \"Oh great, another selfie with your car\",\n",
                "    \"Cricket News Dear Virat sir aaj bhi aap pichle match wali form jaari Rakhe\",\n",
                "]\n",
                "\n",
                "print('\\n─── Inference Demo ───')\n",
                "for ex in examples:\n",
                "    result = predict(ex, best_model, tokenizer, device)\n",
                "    print(f\"  {result['label']:>15} ({result['confidence']})  │  {result['text']}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}